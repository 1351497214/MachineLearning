{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(37) # 使得每次运行得到的随机数都一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析数据集\n",
    "from sklearn import datasets # sklearn自带的datasets中就有Boston房价数据集\n",
    "housing_data=datasets.load_boston()\n",
    "dataset_X=housing_data.data # 获取影响房价的特征向量，作为feaure X\n",
    "dataset_y=housing_data.target # 获取对应的房价，作为label y\n",
    "# print(dataset_X.shape) # (506, 13) # 一共有506个样本，每个样本有13个features\n",
    "# print(dataset_y.shape) # (506,)\n",
    "# print(dataset_X[:5,:]) # 打印看看features的数值类型和大小，貌似已经normalize.\n",
    "\n",
    "# 将整个数据集划分为train set 和test set两部分\n",
    "#\n",
    "from sklearn.utils import shuffle\n",
    "dataset_X,dataset_y=shuffle(dataset_X,dataset_y)\n",
    "# print(dataset_X[:5,:]) # 确认dataset_X 的确发生了shuffle\n",
    "num_split=int(0.8*len(dataset_X))\n",
    "train_X,train_y=dataset_X[:num_split],dataset_y[:num_split]\n",
    "test_X,test_y=dataset_X[num_split:],dataset_y[num_split:]\n",
    "# print(train_X.shape) # (404, 13)\n",
    "# print(test_X.shape) # (102, 13)\n",
    "\n",
    "# 上面的数据集划分也可以采用下面的方法：\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# dataset_y=dataset_y[:,np.newaxis]\n",
    "# dataset=np.hstack((dataset_X,dataset_y))\n",
    "# print(dataset.shape)\n",
    "# print(dataset[:,:3])\n",
    "# train_set,test_set=train_test_split(dataset,test_size=0.2,random_state=37)\n",
    "# print(train_set.shape) # (404, 14)\n",
    "# print(test_set.shape) # (102, 14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树回归模型的评测结果----->>>\n",
      "均方误差MSE：13.33\n",
      "解释方差分：0.81\n"
     ]
    }
   ],
   "source": [
    "# 构建决策树回归模型\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision_regressor=DecisionTreeRegressor(max_depth=4) # 最大深度确定为4\n",
    "decision_regressor.fit(train_X,train_y) # 对决策树回归模型进行训练\n",
    "\n",
    "# 使用测试集来评价该决策树回归模型\n",
    "predict_test_y=decision_regressor.predict(test_X)\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "print('决策树回归模型的评测结果----->>>')\n",
    "print('均方误差MSE：{}'.format(\n",
    "    round(metrics.mean_squared_error(predict_test_y,test_y),2)))\n",
    "print('解释方差分：{}'.format(\n",
    "    round(metrics.explained_variance_score(predict_test_y,test_y),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth: 2, MSE: 23.83, EVS: 0.62\n",
      "depth: 3, MSE: 20.98, EVS: 0.68\n",
      "depth: 4, MSE: 13.33, EVS: 0.81\n",
      "depth: 5, MSE: 13.00, EVS: 0.83\n",
      "depth: 6, MSE: 14.36, EVS: 0.83\n",
      "depth: 7, MSE: 11.73, EVS: 0.86\n",
      "depth: 8, MSE: 16.18, EVS: 0.83\n",
      "depth: 9, MSE: 15.74, EVS: 0.83\n",
      "depth: 10, MSE: 14.67, EVS: 0.83\n",
      "depth: 11, MSE: 15.02, EVS: 0.84\n"
     ]
    }
   ],
   "source": [
    "# 第一种优化方法：改变max depth来降低MSE,提高解释方差分\n",
    "for depth in range(2,12):\n",
    "    decision_regressor_test=DecisionTreeRegressor(max_depth=depth) \n",
    "    decision_regressor_test.fit(train_X,train_y)\n",
    "    predict_test_y2=decision_regressor_test.predict(test_X)\n",
    "    print('depth: {}, MSE: {:.2f}, EVS: {:.2f}'.format(\n",
    "        str(depth), metrics.mean_squared_error(predict_test_y2,test_y),\n",
    "        metrics.explained_variance_score(predict_test_y2,test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost决策树回归模型的评测结果----->>>\n",
      "均方误差MSE：7.87\n",
      "解释方差分：0.9\n"
     ]
    }
   ],
   "source": [
    "# 第二种优化方法：通过AdaBoost算法来提高模型准确度\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ada_regressor=AdaBoostRegressor(DecisionTreeRegressor(max_depth=7),n_estimators=400)\n",
    "ada_regressor.fit(train_X,train_y)\n",
    "\n",
    "# 查看使用AdaBoost算法后模型的MSE 和EVS\n",
    "predict_test_y=ada_regressor.predict(test_X)\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "print('AdaBoost决策树回归模型的评测结果----->>>')\n",
    "print('均方误差MSE：{}'.format(\n",
    "    round(metrics.mean_squared_error(predict_test_y,test_y),2)))\n",
    "print('解释方差分：{}'.format(\n",
    "    round(metrics.explained_variance_score(predict_test_y,test_y),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
